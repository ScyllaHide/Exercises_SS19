% This work is licensed under the Creative Commons
% Attribution-NonCommercial-ShareAlike 4.0 International License. To view a copy
% of this license, visit http://creativecommons.org/licenses/by-nc-sa/4.0/ or
% send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\section{Präsenzübung 1}
\subsection{Aufgabe 1.1}

\begin{enumerate}[label=\alph*)]
	\item Es seien $M,N$ beliege Mengen und $T: M \to N$ eine Abbildung. Zeigen Sie: $T^{-1}(A^C) = (T^{-1}(A))^C$.
	Erinnerung an Schreibweise $T^{-1}(A) = \set{a \in M \colon T(a) \in B}$ und $T(A) := \set{T(a) \colon a \in A}$ und setze $A \subset N$ und $B \subset M$.
	\item Es seien $(\Omega_1, \F_1)$, $(\Omega_2, \F_2)$ und $(\Omega_3, \F_3)$ messbare Räume (oder auch Messräume) und $f: (\Omega_1, \F_1) \to (\Omega_2, \F_2)$, $g: (\Omega_1, \F_1) \to (\Omega_2, \F_2)$ messbare Funktionen. Zeigen Sie, dass dann auch die Komposition $g\circ f: (\Omega_1, \F_1) \to (\Omega_3, \F_3)$ messbar ist.
	\item Es sei $\Omega$ eine überabzählbare Menge. Zeigen Sie, dass
	\begin{align*}
		\F := \set{A \subset \Omega: A \text{ ist abzählbar } \vee A^{C} \text{ ist abzählbar}}
	\end{align*}
	eine $\sigma$-Algebra über $\Omega$ ist.
\end{enumerate}
%TODO check if I can make this more sound! there is still a problem at the end of the proof with the way it is defined.
\begin{proof}
	\begin{enumerate}[label=\alph*)]
		\item 
		\begin{align*}
			\set{a \in T^{-1}(A^C)} &\gdw \exists b \in B^C : T(a) = b\\
			&\overset{(!)}{\gdw} \exists c \in B : T(a) = c\\
			&\gdw a \not\in \set{T \in A}\\
			&\gdw a \in \set{T \in A}^C = a \in (T^{-1}(A))^C
		\end{align*}
		Nun muss man sich noch $(!)$ klar machen. Das ganz gilt, da $T$ eine Abbildung ist, also wird jedem Element in $M$ genau ein Element in $N$ zugeordnet.\\
		``$\Rightarrow$'' folgt aus der Eigenschaft, dass für jedes Element in $M$ \emph{höchstens} ein Element in $N$ abgebildet wird.\\
		``$\Leftarrow$'' Analog Argument.
		\item $\forall A \in \F_3$ gilt $(g\circ f)^{-1}(A) = f^{-1}\circ \underbrace{\in \F_2}_{g^{-1}(A)} \in f^{-1}(\F_2)\subset \F_1$
		\item Dafür muss man nur die drei Axiome der $\sigma$-Algebra nachweisen.
		\begin{itemize}
			\item $\Sigma_1$: $\Omega^C = \emptyset$ ist abzählbar $\Rightarrow \Omega \in \F$
			\item $\Sigma_2$: 
			\begin{align*}
				A \in \F &\gdw \#A \le \#\N \oder \# A^C \le \# \N\\
				&\gdw \# A^C \le \# \N \oder \# (A^C)^C = A \le \#\N\\
				&\gdw A^C \in \F
			\end{align*}
			\item $\Sigma_3$: Sei $\brackets{A_n}_{n \in \N} \subset \F$. Zwei Fälle sind zu bearbeiten.
			\begin{itemize}
				\item[\textit{Fall 1:}] Es werden genau die Mengen $A_n$ ausgewählt, welche abzählbar sind. Dann folgt aber das auch die Vereinigung $\bigcup_{n\in \N} A_n$ von abzählbare vielen abzählbaren Mengen eine abzählbare Menge sind, also $A \in \F$.
				\item[\textit{Fall 2:}] Eine Menge, z.B. $A_{n_0}$, ist überabzählbar. Dann folgt aber aus der Definition von $\F$, das Komplement von $A_{n_0}^C$ abzählbar ist. Damit folgt für die Folge, dass $\brackets{A_n}_{n \in \N}$ gilt.
				\begin{align*}
					\brackets{\bigcup_{n\in \N} A_n}^C = \bigcap_{n\in \N} A_n^C \subset A^C_{n_0},
				\end{align*} 
				damit ist auch das Komplement von $A = \bigcup_{n\in \N}A_n$ abzählbar und liegt in $\F$.
			\end{itemize}
		Damit wurde nachgewiesen, das $\F$ eine $\sigma$-Algebra ist.
		\end{itemize}
	\end{enumerate}
\end{proof}

%%%%%%%%%%%%%%%%%%%% Aufgabe 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Aufgabe 1.2}
\begin{enumerate}
	\item Es sei $(\Omega, \F, \Meas)$ ein WRaum und $A,B,C \in \F$ drei Ereignisse. Beschreiben Sie mengentheoretisch folgende Ereignisse:
	\begin{enumerate}
		\item es tritt nur $A$ ein
		\item $A$ und $B$ treten ein, aber $C$ nicht
		\item Mindestens eins der Ereignisse tritt ein
		\item Mindestens zwei der Ereignisse treten ein
		\item $A,B,C$ treten alle ein
		\item Keines der drei Ereignisse $A,B,C$ tritt ein
		\item Höchstens ein Ereigniss tritt ein
		\item Höchstens zwei Ereignisse treten ein
		\item Genau zwei Ereignisse treten ein
		\item Höchstens drei der Ereignisse tretten ein.
	\end{enumerate}
	\item Es seien $A_1,A_2, \dots$ Ereignisse. Interpretieren Sie folgende Ereignisse:
		\begin{align*}
			\ul{A}:= \liminf_{n \to \infty} A_n = \bigcup_{n=1}^{\infty}\bigcap_{k=n}^{\infty} A_k, \quad \overline{A}:= \limsup_{n \to \infty} A_n = \bigcup_{n=1}^{\infty}\bigcap_{k=n}^{\infty} A_k
		\end{align*}
\end{enumerate}

\begin{lösung}
	\begin{enumerate}
		\item Im wesentlichen sind das eigentlich nur Teilmengen der Potenzmenge von $\pows(\Omega)$, wobei $\Omega = \set{A,B,C}$ ist? (Bin mir dabei gar nicht recht sicher, könnte auch eine Partition von $\pows(\Omega)$) sein.
		\begin{enumerate}
			\item $\set{A}$
			\item $\set{A,B}$
			\item $\set{A,B,C, \set{A,B}, \set{B,C}, \set{A,C}, \set{A,B,C}}$
			\item $\set{\set{A,B}, \set{B,C}, \set{A,C}, \set{A,B,C}}$
			\item $\set{A,B,C}$
			\item $\set{\emptyset}$
			\item $\set{\emptyset, A, B, C}$
			\item $\set{\set{A,B}, \set{B,C}, \set{A,C}, \emptyset, A,B,C}$
			\item $\set{\set{A,B}, \set{B,C}, \set{A,C}}$
			\item $\set{\set{A,B,C}}$
		\end{enumerate}
	\item $\dots$ %TODO!
	\end{enumerate}
\end{lösung}

%%%%%%%%%%%%%%%%%%%% Aufgabe 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Aufgabe 1.3}

\begin{enumerate}
	\item Es sei $\Meas$ ein WMaß auf $(\Omega, \F)$ und $A,B,A_1,A_2,\dots \in \F$ beliebige Ereignisse. Zeigen Sie:
	\begin{enumerate}
		\item $\Meas(\emptyset) = 0$,
		\item $\Meas(A\cup B) + \Meas(A\cap B) = \Meas(A) + \Meas(B)$ (endliche Additivität), insbesondere $\Meas(A) + \Meas(A^C) = 1$,
		\item Aus $A \subseteq B$ folgt $\Meas(A) \le \Meas(B)$ (Monotonie),
		\item $\sigma$-Subadditivität
		\begin{align*}
			\Meas\left( \bigcup_{i \ge 1} A_i\right) \le \sum_{i\ge 1} \Meas(A_i),
		\end{align*}
		\item $\sigma$-Stetigkeit, d.h. $A_n \uparrow A$, d.h. $A_1 \subseteq A_2 \subseteq \dots$ und $A = \bigcup_{i \ge 1} A_i$ (oder $A_n \downarrow A$, d.h. $A_1 \supseteq A_2 \supseteq \dots$ und $A = \bigcap_{i \ge 1} A_i$), dann
		\begin{align*}
			\liminf_{i \to \infty} \Meas(A_i) = \Meas(A).
		\end{align*}
	\end{enumerate}
	\item Es sei $(\Omega, \F, \Meas)$ ein WRaum und $A,B \in \F$ zwei Ereignisse mit $\Meas(A) = 0.6$ und $\Meas(B) = 0.4$, sowie $\Meas(A\cap B) = 0.2$. Bestimmen Sie die Wahrscheinlichkeiten
	\begin{align*}
		\Meas(A\cup B), \quad \Meas(B^C), \quad \Meas(A^C \cap B), \quad \Meas(A \cup B^C), \quad \Meas(A^C \cap B^C).
	\end{align*}
\end{enumerate}

\begin{proof}
	\begin{enumerate}
		\item 
		\begin{enumerate}
			\item Behauptung: $\Meas(\emptyset) = 0$
			\begin{align*}
			\emptyset = \bigcup_{n=1}^{\infty} \emptyset\qquad 
			\Meas(\emptyset) = \Meas\left(\bigcup_{n=1}^{\infty}\right) = \sum_{i= 1}^{\infty} \Meas(\emptyset) \le 1.
			\end{align*}
			\item ... %TODO other points, i have as picture!
		\end{enumerate}
	\item $\dots$ %TODO No idea right now, later.
	\end{enumerate}
\end{proof}

%%%%%%%%%%%%%%%%%%%% Aufgabe 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Aufgabe 1.4}
Es sei $X$ eine stetige, reelle Zufallsvariable ($X: \R_{+} \to \R_{+}$) mit Wahrscheinlichkeitsdichte
\begin{align*}
	f: \R_{+} \to \R_{+} \mit f(x) = \frac{1}{2c} e^{-cx}
\end{align*}

\begin{enumerate}[label=\alph*)]
	\item Bestimme den Paramter $c$!
	\item Wie sieht die Verteilungsfunktion von $X$ aus?
\end{enumerate}

\begin{lösung}
	\begin{enumerate}[label=\alph*)]
		\item Nach auswerten des Integrals über $\R_{+}$ und $f$, ergibt sich $c = \sfrac{1}{\sqrt{2}}$. %TODO formulate this. 
		Sei $\Meas$ das WMaß, was normiert ist zu $1$, d.h. $\Meas(\R_{+}) \overset{!}{=}1 (N)$. Damit lässt sich dann $c$ bestimmen:
		\begin{align*}
			\Meas(\R_{+}) &= \int_{\R_{+}} \frac{1}{2c} e^{-cx} dx\\
			&= \frac{1}{2c} \int_{0}^{\infty}  e^{-cx} dx \\
			&= \frac{1}{2c} \big[-\frac{1}{c} e^{-cx}\big]_{0}^{\infty}\\
			&= -\frac{1}{2c^2} \big(\lim\limits_{\alpha \to \infty} e^{-c\alpha} - e^{-c\cdot0}\big)\\
			&= \frac{1}{2c^2} \overset{(N)}{\Rightarrow} c = \frac{1}{\sqrt{2}} 
		\end{align*}
		\item Damit gibt es folgenden WRaum $(\Omega, \borel(\R_{+}),\Meas)$ auf diesem soll sich die Verteilungsfunktion befinden. Nach Definition gilt: 
		\begin{align*}
			F_{\Meas \circ X^{-1}} = F_{X}: \R_{+} \to [0,1] \mit F: d \to \Meas((X \le d))\\
			\text{Im dem Fall sieht das so aus } F_{X}(d) = \int_{0}^{d} \frac{1}{2c} e^{-cx} dx. %TODO verify this!
		\end{align*}
		%TODO maybe draw a plot of this thing?
	\end{enumerate}
\end{lösung}


%\begin{align*}
%	L_0^2:=\big\lbrace X\in L_2:\E[X]=0\big\rbrace
%\end{align*}
%der Raum der zentrierten quadrat-integrierbaren Zufallsvariablen. 
%Für diesen gilt:
%\begin{enumerate}[label=\alph*)]
%	\item $L_0^2$ ist ein Hilbertraum mit Skalarprodukt $\Cov(\cdot,\cdot)$.
%	\item Seien $X_1,...,X_n\in L_0^2$. Dann gilt:
%	\begin{align*}
%		\Var\left[\sum\limits_{j=1}^n X_j\right]
%		=\sum\limits_{j=1}^n\left(\Var[X_j]+2\cdot\sum\limits_{k>j}\Cov[X_j,X_k]\right)
%	\end{align*}
%	\item Seien $X_1,...,X_n\in L_0^2$. Dann gilt:
%	\begin{align*}
%		\sqrt{\Var\left[\sum\limits_{j=1}^n X_j\right]}\leq\sum\limits_{j=1}^n \sqrt{\Var[X_j]}
%	\end{align*}
%\end{enumerate}
%
%\begin{proof}
%	\underline{Zeige a):}\\
%	Nutze Untervektorraumkriterium:
%	\begin{itemize}
%		\item $0\in L_0^2$ ist klar.
%		\item Sei $X\in L_0^2$ und $\lambda\in\R$. Dann ist $X\in L_0^2$ wegen
%		\begin{align*}
%			\E[\lambda\cdot X]\stackeq{\text{Lin}}\lambda\cdot\E[X]\stackeq{X\in L_2^0}0
%		\end{align*}
%		\item Seien $X,Y\in L_0^2$. Dann ist $X+Y\in L_0^2$ wegen
%		\begin{align*}
%			\E[X+Y]\stackeq{\text{Lin}}\E[X]+\E[Y]\stackeq{X,Y\in L_0^2}0+0=0
%		\end{align*}
%	\end{itemize}
%	Somit ist $L_0^2$ ein Untervektorraum von $L_2$. Dass
%	\begin{align*}
%		\langle X,Y\rangle:=\Cov(X,Y):=
%		\E\Big[\big(X-\E[X]\big)\cdot\big(Y-\E[Y]\big)\Big]
%		=\E[X\cdot Y]
%		\qquad\forall X,Y\in L_0^2
%	\end{align*}
%	ein Skalarprodukt auf $L_0^2$ ist, ist klar, das es mit dem $L^2$-Skalarprodukt des Oberraumes $L^2$ übereinstimmt.
%
%	%Gleich vorweg: Die Kovarianz erfüllt sogar auf $L^2$ alle Eigenschaften bis auf positive Definitheit. Diese gilt nur auf $L_0^2$. Deswegen werden im Folgenden die Eigenschaften der Kovarianz allgemeiner gezeigt.
%	%\begin{itemize}
%	%\item Die Kovarianz ist Bilinear, denn für $\lambda\in\R$ und $X,Y,Z\in L_0^2$ gilt
%	%\begin{align*}
%	%\Cov(\lambda\cdot X,Y)
%	%&=\E\Big[\big(\lambda\cdot X-\E[ \lambda\cdot X]\big)\cdot\big(Y-\E[Y]\big)\Big]\\
%	%&=\E\Big[\big(\lambda\cdot\big(X-\E[X]\big)\big)\cdot\big(Y-\E[Y]\big)\Big]\\
%	%&=\lambda\cdot\Cov(X,Y)\\
%	%\Cov(X,\lambda\cdot Y)
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(\lambda\cdot Y-\E[\lambda\cdot Y]\big)\Big]\\
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(\lambda\cdot\big(Y-\E[Y]\big)\big)\Big]\\
%	%&=\lambda\cdot\Cov(X,Y)\\
%	%\Cov(X+Z,Y)
%	%&=\E\Big[\big(X+Z-\E[X+Z]\big)\cdot\big(Y-\E[Y]\big)\Big]\\
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(Y-\E[Y]\big)+\big(Z-\E[Z]\big)\cdot\big(Y-\E[Y]\big)\Big]\\
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(Y-\E[Y]\big)\Big]
%	%+\E\Big[\big(Z-\E[Z]\big)\cdot\big(Y-\E[Y]\big)\Big]\\
%	%&=\Cov(X,Y)+\Cov(Z,Y)\\
%	%\Cov(X,Y+Z)
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(Y+Z-\E[Y+Z]\big)\Big]\\
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(Y-\E[Y]\big)+\big(X-\E[X]\big)\cdot\big(Z-\E[Z]\big)\Big]\\
%	%&=\E\Big[\big(X-\E[X]\big)\cdot\big(Y-\E[Y]\big)\Big]
%	%+\E\Big[\big(X-\E[X]\big)\cdot\big(Z-\E[Z]\big)\Big]\\
%	%&=\Cov(X,Y)+\Cov(X,Z)
%	%\end{align*}
%	%\item Die Kovarianz ist symmetrisch, was man schon an der Definition erkennt: $\Cov(X,Y)=\Cov(Y,X)$
%	%\item Die Kovarianz ist positiv definit:
%	%\begin{align*}
%	%\Cov(X,X)&=\E\Big[\underbrace{\big(X-\E[X]\big)^2}_{\geq0}\Big]\geq0\text{ und}\\
%	%\Cov(X,X)&=0\stackrel{\E[X]=0}{\gdw} X=0\text{ fast sicher}
%	%\end{align*}
%	%\end{itemize}
%	
%	Bleibt noch zu zeigen, dass $L_0^2$ bzgl. der die die Kovarianz induzierten Norm
%	\begin{align*}
%		\Vert X\Vert:=\sqrt{\Cov(X,X)}
%		=\sqrt{\E\Big[\big(X-\E[X]\big)^2\Big]}
%		=\sqrt{\E\Big[X^2\Big]}
%		\qquad\forall X,Y\in L_0^2
%	\end{align*}
%	vollständig ist. 
%	Diese Norm stimmt auf $L_0^2$ mit der bekannten $L^2$-Norm überein. 
%	Und da bekannt ist, dass $\big(L^2,\Vert\cdot\Vert_{L^2}\big)$ ein Banachraum ist, genügt es noch zu zeigen, dass $L_0^2$ abgeschlossen ist.
%	Sei also $(X_n)_{n\in\N}\subseteq L_0^2$ eine Folge mit
%	$X_n\stackrel{n\to\infty}{\longrightarrow}X\in L^2$.
%	Dann gilt schon $X\in L_0^2$, denn:
%
%	%Angenommen $\E[X]\neq0$. Dann gibt es $c>0$ so, dass
%	%\begin{align*}
%	%0<c\leq \big(\E[X]\big)^2&=\Big(\E[X]\cdot\big(\E[X-X_n+X_n]\big)\Big)\\
%	%&=\big(\E[X]\cdot\E[X-X_n]+\E[X]\cdot\underbrace{\E[X_n]}_{=0}\big)\\
%	%&=\E[X]\cdot\E[X-X_n]\\
%	%&\leq\E\big[|X|\big]\cdot\E\big[|X-X_n|\big]
%	%\stackrel{n\to\infty}{\longrightarrow}0
%	%\end{align*}
%	%Dies ist ein Widerspruch. Folglich $\E[X]=0$ und somit $X\in L_0^2(\Omega)$.\\
%
%	\begin{align*}
%		E[X]
%		&=\E[X-X_n+X_n]\\ 
%		&=\E[X-X_n]+\underbrace{\E[X_n]}_{=0}\\
%		\implies
%		\big|\E[X]\big|&\leq \E\big[|X-X_n|\big]
%		\overset{\text{Jensen}}{\leq}
%		\sqrt{\E\big[(X_n-X)^2\big]}
%		\overset{n\to\infty}{\longrightarrow} 0\\
%		\implies
%		\E[X]&=0
%	\end{align*}
%
%	\underline{Zeige b):} 
%	Für $X,Y\in L_0^2$ gilt $\Var[X]=\E\big[X^2\big]$ und $\Cov[X,Y]=\E[X\cdot Y]$. 
%	Damit folgt
%	\begin{align*}
%		\Var\left[\sum\limits_{j=1}^n X_j\right]
%		&=\E\left[\left(\sum\limits_{j=1}^n X_j\right)^2\right]\\
%		&=\E\left[\sum\limits_{j=1}^n\sum\limits_{k=1}^n X_j\cdot X_k\right]\\
%		&=\sum\limits_{j=1}^n\sum\limits_{k=1}^n \E[X_j\cdot X_k]\\
%		&=\sum\limits_{j=1}^n\left(
%		\sum\limits_{\begin{subarray}{c}k=1\\ k=j\end{subarray}}^n \E[X_j\cdot X_k]
%		+\sum\limits_{\begin{subarray}{c}k=1\\ k\neq j\end{subarray}}^n \E[X_j\cdot X_k]\right)\\
%		&=\sum\limits_{j=1}^n\left(\underbrace{\E\big[X_j^2\big]}_{=\Var[X]}+2\cdot\sum\limits_{k>j}\underbrace{\E[X_j\cdot X_k]}_{=\Cov(X_j,Y_k)}\right)
%	\end{align*}
%
%	Abstrakt als Hilbertraum aufgefasst:
%	\begin{align*}
%		\left\langle\sum\limits_{k},\sum\limits_{k} X_k\right\rangle
%		=\sum\limits_k\left\langle X_k,X_k\right\rangle+2\cdot\sum\limits_{i<j}\left\langle X_i,X_j\right\rangle
%	\end{align*}
%
%	\underline{Zeige c):}
%	\begin{align*}
%		\sqrt{\Var\left[\sum\limits_{j=1}^n X_j\right]}
%		=\sqrt{\E\left[\left(\sum\limits_{j=1}^n\right)^2\right]}
%		=\left\Vert\sum\limits_{j=1}^n X_i\right\Vert
%		\overset{\Delta\text{-Ungl}}{\leq}
%		\sum\limits_{j=1}^n\Vert X_j\Vert
%		=\sum\limits_{j=1}^n\sqrt{\Var[X_j]}
%	\end{align*}
%\end{proof}
%
%\subsection{Aufgabe 1.2}
%Seien $X,Y\in L_2(\A)$ und $\F\subseteq\A$ Unter-$\sigma$-Algebra von $\A$. 
%\textbf{Bedingte Varianz} und \textbf{bedingte Kovarianz} von $X$ bzw. $X,Y$ unter $\F$ sind definiert als
%\begin{align*}
%	\Var[X~|~\F]&:=\E\Big[\big(X-\E[X~|~\F]\big)^2~\Big|~\F\Big]\\
%	\Cov[X,Y~|~\F]&:=\E\Big[\big(X-\E[X~|~\F]\big)\cdot\big(Y-\E[Y~|~\F]\big)~\Big|~\F\Big]
%\end{align*}
%Dann gelten die Sätze der \textbf{totalen Varianz} bzw. \textbf{totalen Kovarianz}:
%\begin{align*}
%	\Var[X]&=\E\big[\Var[X~|~\F]\big]+\Var\big[\E[X~|~\F]\big]\\
%	\Cov[X,Y]&=\E\big[\Cov[X,Y~|~\F]\big]+\Cov\big[\E[X~|~F],\E[Y~|~\F]\big]
%\end{align*}
%
%\begin{proof}
%	\underline{Zur ersten Gleichung:}\\
%	Aus der Nebenrechnung
%	\begin{align}\label{eqTotaleVarianz}
%		\Var[X~|~\F]
%		\overset{\text{Def}}&=
%		\E\Big[\big(X-\E[X~|~\F]\big)^2~\Big|~\F\Big]\\\nonumber
%		\overset{\text{}}&=
%		\E\Big[X^2-2\cdot X\cdot \E[X~|~\F]+\big(\E[X~|~\F]\big)^2~\Big|~\F\Big]\\\nonumber
%		\overset{\text{Lin}}&=
%		\E\big[X^2~\big|~\F\big]-2\cdot\E\big[X\cdot\E[X~|~\F]\big]+\E\Big[\big(\E[X~|~\F]\big)^2~\Big|~\Big]\\\nonumber
%		\overset{\text{Pull-out}}&=
%		\E\big[X^2~\big|~\F\big]-2\cdot\E[X~|~\F]\cdot\E[X~|~\F]+
%		\E[X~|~\F]\cdot\underbrace{\E\big[\E[X~|~\F]~\big|~\F\big]}_{\stackeq{\text{Tower}}\E[X~|~\F]}\\\nonumber
%		&=
%		\E\big[X^2~\big|~\F\big]-\big(\E[X~|~\F]\big)^2 
%	\end{align}
%	folgt
%	\begin{align*}
%		&\E\big[\Var[X~|~\F]\big]+\Var\big[\E[X~|~\F]\big]\\
%		&=\E\big[\Var[X~|~\F]\big]+\E\Big[\big(\E[X~|~\F]\big)^2\Big]-\Big(\E\big[\E[X~|~\F]\big]\Big)^2\\
%		\overset{\eqref{eqTotaleVarianz}}&=
%		\E\Big[\E\big[X^2~\big|~\F\big]-\big(\E[X~|~\F]\big)^2 \Big]+
%		\E\Big[\big(\E[X~|~\F]\big)^2\Big]-\Big(\E\big[\E[X~|~\F]\big]\Big)^2\\
%		\overset{\text{Lin}}&=
%		\E\Big[\E\big[X^2~\big|~\F\big]\Big]\underbrace{-\E\Big[\big(\E[X~|~\F]\big)^2 \Big]+
%		\E\Big[\big(\E[X~|~\F]\big)^2\Big]}_{=0}-\Big(\E\big[\E[X~|~\F]\big]\Big)^2\\
%		&=\E\Big[\E\big[X^2~\big|~\F\big]\Big]-\Big(\E\big[\E[X~|~\F]\big]\Big)^2\\
%		\overset{\text{Tower}}&=
%		\E[X^2]-\big(\E[X]\big)^2\\
%		&=\Var[X]
%	\end{align*}
%
%	\underline{Zur zweiten Gleichung:} 
%
%	Zunächst gilt die \textit{Polarisation:} 
%	\begin{align*}
%		\Cov(X,Y)=\frac{1}{2}\cdot\big(\underbrace{\Var[X+Y]}_{=\langle X+Y,X+Y\rangle}-\underbrace{\Var[X]}_{=\langle X,X\rangle}-\underbrace{\Var[Y]}_{=\langle Y,Y\rangle}\big)
%	\end{align*}
%	Setze der Kürze halber $X_F:=\E[X~|~\F], Y_F:=\E[Y~|~\F]$. 
%	Dann gilt:
%	\begin{align*}
%		&\E[\Cov(X,y~|~\F)]\\
%		&=\E[\E[(X-X_F)\cdot(Y-Y_F)~|~\F]]\\
%		\overset{\text{Tower}}&=
%		\E[(X-X_F)\cdot(Y-Y_F)]\\
%		&=\E[X\cdot Y]-\E[\E[X~|~F]\cdot Y]-\E[X\cdot\E[Y~|~\F]]+\E[\E[X~|~\F]\cdot\E[Y~|~\F]]\\
%		\overset{\text{Sym}}&=
%		\E[X\cdot Y]-\E[X_F\cdot Y_F]\\
%		&=\Cov(X,Y)+\E[X]\cdot\E[Y]-\E[X_F\cdot Y_F]\\
%		\overset{\text{Tower}}&=
%		\Cov(X,Y)+\E[X_F]\cdot\E[Y_F]-\E[X_F\cdot Y_F]\\
%		&=\Cov(X,Y)-\Cov(\E[X~|~\F],\E[Y~|~\F]]
%	\end{align*}
%	Umstellen impliziert die Behauptung.
%\end{proof}
%
%\subsection{Aufgabe 1.3}
%Sei 
%$M=\begin{pmatrix}
%	A & B\\ C & D
%\end{pmatrix}$ eine quadratische, in Blöcke unterteilte Matrix von vollem Rang, wobei $A$ und $D$ ebenfalls quadratisch und von vollem Rang seien. 
%Die Ausdrücke
%\begin{align*}
%	(M/A):=\left(D-C\cdot A^{-1}\cdot B\right),\qquad(M/D):=\left(A-B\cdot D^{-1}\cdot C\right)
%\end{align*}
%heißen \textbf{Schurkomplement} von $A$ in $M$ bzw. 
%$D$ in $M$. Dann gilt:
%\begin{enumerate}[label=\alph*)]
%	\item $\begin{aligned}
%		M^{-1}=\begin{pmatrix}
%			(M/D)^{-1} & -A^{-1}\cdot B\cdot(M/A)^{-1}\\
%			-D^{-1}\cdot C\cdot(M/D)^{-1} & (M/A)^{-1}
%		\end{pmatrix}
%	\end{aligned}$
%	\item Sei $M$ nun symmetrisch, d.h. $A$ und $D$ sind symmetrisch und $C=B^T$. Dann gilt:
%	\begin{align*}
%		(x^T,y^T)\cdot M^{-1}\cdot\begin{pmatrix}
%			x\\y
%		\end{pmatrix}-y^T\cdot D^{-1}\cdot y=\tilde{x}^T\cdot(M/D)^{-1}\cdot\tilde{x}
%	\end{align*}
%	mit $\tilde{x}=\left(x-B\cdot D^{-1}\cdot y\right)$ für alle $x,y$ mit passender Dimension.
%	\item Es sei $(X,Y)$ multivariat normalverteilt mit Erwartungswert 0 und positiv definiter Kovarianzmatrix 
%	$\Sigma=\begin{pmatrix}
%		\Sigma_X & \Sigma_{XY}\\ 
%		\Sigma_{XY}^T & \Sigma_Y
%	\end{pmatrix}$. 
%	Dann ist $X$ bedingt auf $Y$ normalverteilt mit $\E[X~|~Y]=\Sigma_{XY}\cdot\Sigma_{Y}^{-1}$ und Kovarianzmatrix $(\Sigma/\Sigma_Y)$\\
%	Hinweis: Es gilt $\det(\Sigma)=\det(\Sigma_Y)\cdot\det(\Sigma/\Sigma_Y)$.
%\end{enumerate}
%
%\begin{proof}
%	\underline{Zeige a):}\\
%	Beachte: Matrixmultiplikation gilt Blockweise.
%	\begin{align*}
%		&M\cdot M^{-1}\\
%		&=\begin{pmatrix}
%			A & B\\ C & D
%		\end{pmatrix}\cdot\begin{pmatrix}
%			(A-B\cdot D^{-1}\cdot C)^{-1} & -A^{-1}\cdot B\cdot(D-A\cdot C^{-1}\cdot B)^{-1}\\
%			-D^{-1}\cdot C\cdot(A-B\cdot D^{-1}\cdot C)^{-1} & (D-C\cdot A^{-1}\cdot B)^{-1}
%		\end{pmatrix}\\
%		&=\begin{pmatrix}
%			(\ast) & 0\\
%			0 & (\ast\ast)
%		\end{pmatrix}\\
%		(\ast)
%		&=A\cdot(A-B\cdot D^{-1}\cdot C)^{-1}-B\cdot D^{-1}\cdot C(A-B\cdot D{-1}\cdot C)^{-1}\\
%		&=(A-B\cdot D^{-1}\cdot C)\cdot(A-B\cdot D^{-1}\cdot C)^{-1}\\
%		&=I\\
%		(\ast\ast)
%		&=(-C\cdot A^{-1}\cdot B+D)\cdot(D-C\cdot A^{-1}\cdot B)^{-1}\\
%		&=I
%	\end{align*}
%
%	\underline{Zeige b):}
%	\begin{align}\label{3b1}\tag{$\ast$} 
%		&-D^{-1}\cdot B^T\cdot(M/D)^{-1}
%		=-(M/A)^{-1}\cdot B^T\cdot A^{-1}\\\nonumber
%		&\implies
%		(M/A)\cdot D^{-1}\cdot B^T=B^T\cdot A^{-1}\cdot(M/D)\\\nonumber
%		&\implies
%		(D-B^T\cdot A^{-1}\cdot B)\cdot D^{-1}\cdot B^T=B^T\cdot A^{-1}\cdot(A-B\cdot D^{-1}\cdot B^T)\\\nonumber
%		&\implies
%		B^T-B^T\cdot A^{-1}\cdot B\cdot D^{-1}\cdot B^T
%		=B^T-B^T\cdot A^{-1}\cdot B\cdot D^{-1}\cdot B^T
%	\end{align}
%
%	\begin{align*}
%		M^{-1}
%		&=\begin{pmatrix}
%			(M/D)^{-1} & -A^{-1}\cdot B\cdot(M/A)^{-1}\\
%			-D^{-1}\cdot B^T\cdot(M/D)^{-1} & (M/A)^{-1}
%		\end{pmatrix}\\
%		\overset{\eqref{3b1}}&=
%		\begin{pmatrix}
%			(M/D)^{-1} & -A^{-1}\cdot B\cdot(M/A)^{-1}\\
%			-(M/A)^{-1}\cdot B^T\cdot A^{-1} & (M/A)^{-1}
%		\end{pmatrix}
%	\end{align*}
%	Zu zeigen:
%	\begin{align*}
%		\begin{pmatrix}
%			x\\ 
%			y
%		\end{pmatrix}\cdot M^{-1}\cdot\begin{pmatrix}
%			x\\ 
%			y
%		\end{pmatrix}-y^T\cdot D^{-1}\cdot y=\tilde{x}^T\cdot (M/D)^{-1}\cdot\tilde{x}
%		\mit\tilde{x}=x-B\cdot D^{-1}\cdot y
%	\end{align*}
%	Linke Seite:
%	\begin{align*}
%		x^T\cdot(M/D)^{-1}\cdot x-2 y^T\cdot\underbrace{(M/A)^{-1}\cdot B^T\cdot x}_{\text{wegen \eqref{3b1}}}\cdot x+y^T\cdot(M/A)^{-1}\cdot y-y^T\cdot D^{-1}\cdot y
%	\end{align*}
%	Rechte Seite:
%	\begin{align*}
%		x^T\cdot(M/D)^{-1}\cdot x-2 y^T\cdot D^{-1}\cdot B^T\cdot(M/D)^{-1}\cdot x+\\
%		+y^T\cdot D^{-1}\cdot B^T\cdot(M/D)^{-1}\cdot B\cdot D^{-1}\cdot y
%	\end{align*}
%	Noch zu zeigen
%	\begin{align*}
%		(M/A)^{-1}-D^{-1}
%		&=D^{-1}\cdot B^T\cdot(M/D)^{-1}\cdot B\cdot D^{-1}\\
%		&\implies %von links \cdot(M/A) und von rechts \cdot D
%		D-(M/A)=(M/A)\cdot\underbrace{ D^{-1}\cdot B^T\cdot(M/D)^{-1}}_{\stackrel{\eqref{3b1}}(M/A)^{-1}\cdot B^T\cdot A^{-1}}\cdot B
%		\\
%		&\implies
%		B^T\cdot A^{-1}\cdot B=B^T\cdot A^{-1}\cdot B
%	\end{align*}
%	
%	\underline{Zeige c):}
%	\begin{align*}
%		f_{X|Y}(x,y)
%		&=\frac{f_{XY}(x,y)}{f_Y(y)}\\
%		&=\frac{(2\cdot\pi)^{-\frac{m+n}{2}}\cdot\det(\Sigma_Y)}{\det(\Sigma)\cdot(2\cdot\pi)^{-\frac{n}{2}}}
%		\cdot\exp\left(-\frac{1}{2}\cdot\left(\begin{pmatrix}
%			x\\ 
%			y
%		\end{pmatrix}^T\cdot\Sigma^{-1}\cdot\begin{pmatrix}
%			x\\ 
%			y
%		\end{pmatrix}-y^T\cdot\Sigma_Y\cdot y\right)\right)\\
%		\overset{\text{(b)}}&=
%		\frac{(2\cdot\pi)^{-\frac{m}{2}}}{\det(\Sigma/\Sigma_Y}\cdot\exp\left(-\frac{1}{2}\cdot\tilde{x}^T\cdot(\Sigma/\Sigma_Y)^{-1}\cdot\tilde{x}\right)
%		\mit\tilde{x}=x-\Sigma_{XY}\cdot\Sigma_{Y}^{-1}\cdot y
%	\end{align*}
%	ist Dichte von 
%	\begin{align*}
%		\mathcal{N}\Big(\Sigma_{XY}\cdot\Sigma_Y^{-1}\cdot y,(\Sigma/\Sigma_Y)\Big)
%	\end{align*}
%\end{proof}
%
%\subsection{Aufgabe 1.4}
%In einer bestimmten Population sei das Alter $X$ bei erstmaliger Berufsunfähigkeit exponentialverteilt mit Parameter $\lambda>0$. 
%Für eine Versicherungsgesellschaft die gegen Berufsunfähigkeit versichert ist das mittlere Alter bei Eintritt der Berufsunfähigkeit von Bedeutung, 
%unter der Bedingung dass die Berufsunfähigkeit zwischen den Altersgrenzen $0\leq a\leq b$ eintritt.\\
%Bestimme diesen bedingten Erwartungswert $\E[X~|~a\leq X\leq b]$.
%
%\begin{proof}
%	Die Zufallsgröße $X\colon\Omega\to\R$ hat Dichte $f_X(x)=\lambda\cdot\exp(-\lambda\cdot x)$
%	\begin{align*}
%		\E[X~|~a\leq X\leq b]
%		&=\frac{\E\left[X\cdot\indi_{\lbrace a\leq X\leq b\rbrace}\right]}{\P[a\leq X\leq b]}\\
%		&=\frac{\int\limits_a^b \lambda\cdot x\cdot\exp(-\lambda\cdot x)\d x}{\int\limits_a^b\lambda\cdot\exp(-\lambda\cdot x)\d x}\\
%		&=\frac{\int\limits_a^b x\cdot\exp(-\lambda\cdot x)\d x}{\int\limits_a^b\exp(-\lambda\cdot x)\d x}\\
%		&=\frac{\left[\left(-\frac{x}{\lambda}-\frac{1}{\lambda^2}\right)\cdot\exp(-\lambda\cdot x)\right]_{x=a}^b}
%		{\left[-\frac{\exp(-\lambda\cdot x)}{\lambda}\right]_{x=a}^b}\\
%		%&=\frac{
%		%\frac{b\cdot\exp(-\lambda\cdot b)}{\lambda}
%		%+\frac{\exp(-\lambda\cdot b)}{\lambda^2}
%		%-\frac{a\cdot\exp(-\lambda\cdot a)}{\lambda}
%		%-\frac{\exp(-\lambda)\cdot a)}{\lambda^2}
%		%}{
%		%\frac{\exp(-\lambda\cdot b)}{\lambda}
%		%-\frac{\exp(-\lambda\cdot a)}{\lambda}}\\
%		%&=\frac{\left(b+\frac{1}{\lambda}\right)\cdot\exp(-\lambda\cdot b)-\left(a+\frac{1}{\lambda}\right)\cdot\exp(-\lambda\cdot a)}{\exp(-\lambda\cdot b)-\exp(-\lambda\cdot a)}
%		&=\frac{\frac{(a\cdot\lambda+1)\cdot\exp(-\lambda\cdot a)}{\lambda^2}-\frac{(b\cdot\lambda+1)\cdot\exp(-\lambda\cdot b)}{\lambda^2}}{\frac{\exp(-\lambda\cdot a)}{\lambda}-\frac{\exp(-\lambda\cdot b)}{\lambda}}\\
%		&=\frac{(b\cdot\lambda+1)\cdot\exp(a\cdot\lambda)-(a\cdot\lambda+1)\cdot\exp(b\cdot\lambda)}{\big(\exp(a\cdot\lambda)-\exp(b\cdot\lambda)\big)\cdot\lambda}\\
%		\overset{\text{Prof}}&=
%		\frac{1}{\lambda}+\frac{a\cdot\exp(-\lambda\cdot a)-b\cdot\exp(-\lambda\cdot b)}{\exp(-\lambda\cdot a)-\exp(-\lambda\cdot b)}
%	\end{align*}
%\end{proof}
%
%\subsection{Aufgabe 1.5}
%Welche der folgenden in der Vorlesung definierten mathematischen Objekte sind: 
%reelle Zahlen, Zufallsvariablen, messbare Funktionen von $\R\to\R$?
%\begin{align*}
%	\E[X~|~\F],\qquad\P[A~|~B],\qquad \E[X~|~Y=y],\qquad\P[A~|~\F],\qquad\E[X~|~Y]
%\end{align*}
%Wie üblich bezeichnet $\F$ eine $\sigma$-Algebra, $X,Y$ Zufallsvariablen, $y$ eine reelle Zahl und $A,B$ Ereignisse.
%
%\begin{lösung}
%	\begin{align*}
%		&\E[X~|~\F]\in L_2(\Omega,\F,\P)\text{, ist also eine Zufallsvariable}\\
%		&\P[A~|~B]\in[0,1]\subseteq\R\\
%		&\E[X~|~Y=y]:=\int\limits_{\R^m}x\cdot f_{X|Y}(x,y)\d x\in\R\\
%		&\P[A~|~\F]:=\E[\indi_A~|~\F]\in L_2(\Omega,\F,P)\text{ bzw. }\in(0,1)\text{ für festes }\omega\in\Omega\\
%		&\E[X~|~Y]:=\E[X~|~\sigma(Y)]\in L_2(\Omega,\F,\P)\text{, ist also ein Spezialfall der ersten Zeile}
%	\end{align*}
%\end{lösung}
